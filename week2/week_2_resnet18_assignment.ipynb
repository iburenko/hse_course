{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f990dc",
   "metadata": {},
   "source": [
    "In this task you will write a piece of code that\n",
    "creates [ResNet18](https://arxiv.org/abs/1512.03385).\n",
    "ResNet18 is a deep neural networks devised for image classification.\n",
    "\n",
    "## I will write here more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1ac72",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239efb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e81c",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_planes  (int): the number of input channels;\n",
    "        out_palnes (int): the number of output channels;\n",
    "        stride     (int, default=1): stride.\n",
    "        \n",
    "    Return:\n",
    "        A two-dimensional convolutional layer with\n",
    "        `in_planes` input channels, `out_planes` output channels,\n",
    "        kernel size 1, stride size `stride`, 0 padding and\n",
    "        without bias parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Your code here. \n",
    "    \"\"\"\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_planes  (int): the number of input channels;\n",
    "        out_palnes (int): the number of output channels;\n",
    "        stride     (int, default=1): stride.\n",
    "        \n",
    "    Return:\n",
    "        A two-dimensional convolutional layer with\n",
    "        `in_planes` input channels, `out_planes` output channels,\n",
    "        kernel size 3, stride size `stride`, 0 padding and\n",
    "        without bias parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Your code here. \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983db2d",
   "metadata": {},
   "source": [
    "## Resnet18 Basic Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e5f14",
   "metadata": {},
   "source": [
    "![resnet_bb.svg](resnet_bb.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Write a piece of code that creates a Basic block for ResNet\n",
    "    architecture.\n",
    "    Basic block has two computational paths: feedforward path and\n",
    "    residual path (see a picture below).\n",
    "    We will utilise function `downsample_basic_block` from above\n",
    "    as a residual path.\n",
    "    Feedforward path consists of consequitive \n",
    "    application of the following five layers:\n",
    "    1. conv3x3 (use `in_planes`, `planes` and `stride` as \n",
    "                parameters for the conv3x3);\n",
    "    2. Batch normalistaion layer with `planes` features;\n",
    "    3. Activation function;\n",
    "    4. conv3x3 (use `planes`, `planes` as input parameters\n",
    "                to conv3x3, keep `stride` by default)\n",
    "    5. Batch normalisation layer with `planes` features;\n",
    "    \n",
    "    Then sum outputs of the residual and feedforward paths \n",
    "    as the picture suggests and return the activated sum (i.e.\n",
    "    apply the activation function to the sum).\n",
    "    \n",
    "    Provide a possibility to use either ReLU \n",
    "    or LeakyReLU or PReLU inside a Basic block .\n",
    "    \n",
    "    Hint:\n",
    "        When you are using ReLU function from Pytorch use can\n",
    "        specify `inplace=True`. In that case the result of the\n",
    "        activation function will be stored in the same tensor, \n",
    "        i.e. you do not need explicitly assign the result of\n",
    "        the inplace operation to some variable. It could help\n",
    "        to decrease the memory consumption sometimes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, relu_type='relu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes   (int): number of input channels to the block;\n",
    "            planes     (int): number of output channels of the block;\n",
    "            stride     (int, default=1): stride for the first convolutional layer;\n",
    "            downsample (nn.Module, default=None): Convolutional layer to \n",
    "                                                  to downsample the residual connection\n",
    "            rely_type  (str, default='relu'): Type of activation function;\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        assert relu_type in ['relu', 'leaky_relu', 'prelu']\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b08a1",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a20e48",
   "metadata": {},
   "source": [
    "![Activation functions](activations.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17676e64",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        block, \n",
    "        layers, \n",
    "        in_planes=64,\n",
    "        num_classes=100, \n",
    "        relu_type='relu'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ResNet18 comprises an input layer and four consequitive \n",
    "        group of Basic block (layer) that are outputs of the\n",
    "        `self._make_layer` method.\n",
    "        The first layer (not the input one!) has 64 input channels\n",
    "        and twice more, 128, output channels, the next one has 128\n",
    "        input channels and 256 output channels, etc.\n",
    "        The next layer averages should average input tensor over\n",
    "        the spatial dimensions. Let us think that a batch has shape\n",
    "        [B,C,H,W],  B -- the number of elements in the batch;\n",
    "                    C -- the number of output channels;\n",
    "                    H, W -- height and weight, spatial sizes.\n",
    "        After averaging your tensor should have size [B,C,1,1].\n",
    "        The final layer is a linear projection from C-dimensional space\n",
    "        into `num_classes`-dimensional one.\n",
    "        \n",
    "        Hint:\n",
    "            1. You may want to use nn.AdaptiveAvgPool2d;\n",
    "        \"\"\"\n",
    "        \n",
    "        self.in_planes = in_planes\n",
    "        self.relu_type = relu_type\n",
    "        self.downsample_block = downsample_basic_block\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise modules\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block  (nn.Module): Basic block to use;\n",
    "            planes (int): The number of output channels;\n",
    "            blocks (int): How many Basic blocks to repeat;\n",
    "            stride (int, default=1): stride.\n",
    "            \n",
    "        Return:\n",
    "            torch.nn.modules.container.Sequential\n",
    "            \n",
    "        _make_layer method creates `blocks` copies of the `block`.\n",
    "        The first `block` has `self.in_planes` input channels\n",
    "        and `planes` output channels;\n",
    "        other `blocks-1` block have the same number of\n",
    "        input and output channels, namely `planes`.\n",
    "        \n",
    "        Hints:\n",
    "            1. Do not forget to use downsample block.\n",
    "                When do you need to use it?\n",
    "            2. Use a list `layers` to store a list of \n",
    "                required blocks;\n",
    "            3. Once the layer is created do not forget to\n",
    "                change the value of `self.inplanes` since\n",
    "                the number of input channels of the\n",
    "                next layer is the same as the number of \n",
    "                output layers of the current layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define downsample\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define layers\n",
    "        layers = []\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def downsample_basic_block(self, in_planes, out_planes, stride):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes  (int): the number of input channels;\n",
    "            out_palnes (int): the number of output channels;\n",
    "            stride     (int): stride.\n",
    "\n",
    "        Return:\n",
    "            Downsample block comprises two layers:\n",
    "            1. conv1x1(inplanes, outplanes, stride),\n",
    "            2. Batch normalisation block with `outplanes` features.\n",
    "        Hint:\n",
    "            Use nn.Sequential\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" \n",
    "        Your code here. \n",
    "        \"\"\"\n",
    "\n",
    "    def make_input_layer(self, in_channels, out_channels, relu_type):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channles  (int): the number if input channels;\n",
    "            out_channels (int): the number of output channels;\n",
    "            relu_type    (str): type of an activation function.\n",
    "            \n",
    "        Return:\n",
    "            A sequence of layers:\n",
    "            1. 2D convolution layer with `in_channels` input channels;\n",
    "                `out_channels` output channels, `kernel_size` 7,\n",
    "                `stride` 2, `bias` False. \n",
    "                * What `padding` value should\n",
    "                one use in order to have the same spatial size of applying\n",
    "                this convolutional layer? *\n",
    "            2. Batch normalisation layer with out_channels features;\n",
    "            3. Activation function;\n",
    "            4. Maximum pooling with `kernel_size` 3, `stride` 2,\n",
    "                `dilation` 1, `ceil_mode` False.\n",
    "                * Calculate required value for `padding`. *\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(trues, logits):\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return (trues == preds).mean()\n",
    "  \n",
    "def train_epoch(net, dl, criterion, optimizer, device='cuda'):\n",
    "    net.train()\n",
    "    losses = list()\n",
    "    for batch in dl:\n",
    "        images, trues = batch\n",
    "\n",
    "        images = images.to(device)\n",
    "        trues = trues.to(device)\n",
    "\n",
    "        logits = net(images)  \n",
    "\n",
    "        loss = criterion(logits, trues)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "\n",
    "def inference_dl(net, dl, device):\n",
    "    net.eval()\n",
    "    all_trues = list()\n",
    "    all_logits = list()\n",
    "    with torch.no_grad():\n",
    "    for batch in dl:    \n",
    "        images, trues = batch\n",
    "        images = images.to(device)\n",
    "        logits = net(images)\n",
    "\n",
    "        all_trues.append(trues)\n",
    "        all_logits.append(logits)\n",
    "\n",
    "    all_trues = torch.cat(all_trues)\n",
    "    all_logits = torch.cat(all_logits)\n",
    "\n",
    "    return all_trues, all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 16\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8061c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = timm.create_model(\"resnet18\")\n",
    "\n",
    "all_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "train_ds = datasets.CIFAR100('../data', train=True, download=True, transform=all_transforms)\n",
    "test_ds = datasets.CIFAR100('../data', train=False, download=True, transform=all_transforms)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "relu_type = \"prelu\"\n",
    "net = ResNet(BasicBlock, [2, 2, 2, 2], relu_type=relu_type)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_accuracy = list()\n",
    "train_losses = list()\n",
    "data = list()\n",
    "\n",
    "print('Epoch:', -1)\n",
    "trues, logits = inference_dl(net, test_dl, device)\n",
    "\n",
    "trues = trues.cpu().numpy()\n",
    "logits = logits.detach().cpu().numpy()\n",
    "\n",
    "accuracy = calc_accuracy(trues, logits)\n",
    "valid_accuracy.append(accuracy)\n",
    "\n",
    "print('Train loss:', 0)\n",
    "print('Valid accuracy:', accuracy)\n",
    "\n",
    "data.append((trues, logits))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    train_eposc_losses = train_epoch(\n",
    "        net, \n",
    "        train_dl, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    train_losses += train_eposc_losses\n",
    "\n",
    "    trues, logits = inference_dl(net, test_dl, device)\n",
    "\n",
    "    trues = trues.cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    accuracy = calc_accuracy(trues, logits)\n",
    "    valid_accuracy.append(accuracy)\n",
    "\n",
    "    print('Train loss:', np.mean(train_eposc_losses))\n",
    "    print('Valid accuracy:', accuracy)\n",
    "\n",
    "    data.append((trues, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f83b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5 ))\n",
    "plt.plot(train_losses)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30,5 ))\n",
    "plt.plot(valid_accuracy)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "trues = data[-1][0]\n",
    "preds = np.argmax(data[-1][1], axis=1)\n",
    "\n",
    "cn = confusion_matrix(trues, preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ConfusionMatrixDisplay(cn).plot(ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc46b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = data[-1][1]\n",
    "trues = data[-1][0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(logits.flatten(), bins=100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list()\n",
    "neg = list()\n",
    "for i in range(logits.shape[0]):\n",
    "    pos.append(logits[i, trues[i]])\n",
    "    mask = np.array([j != trues[i] for j in range(10)])\n",
    "    neg += list(logits[i][mask])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(pos, bins=100, alpha=0.5, color='green')\n",
    "plt.hist(neg, bins=100, alpha=0.5, color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "\n",
    "def to_binary(trues, logits, class_num):\n",
    "    bin_trues = trues == class_num\n",
    "    bin_logits = logits[:, class_num]\n",
    "    return bin_trues, bin_logits\n",
    "\n",
    "def remove_part(trues, logits, fraq=0.5):\n",
    "    neg_mask = trues == 0\n",
    "    neg_trues = trues[neg_mask]\n",
    "    neg_logits = logits[neg_mask]\n",
    "\n",
    "    pos_mask = (trues == 1) & (np.random.random(size=trues.shape) < fraq)\n",
    "    pos_trues = trues[pos_mask]\n",
    "    pos_logits = logits[pos_mask]\n",
    "\n",
    "    trues = np.concatenate([neg_trues, pos_trues])\n",
    "    logits = np.concatenate([neg_logits, pos_logits], axis=0)\n",
    "\n",
    "    return trues, logits\n",
    "\n",
    "def binary_accuracy(trues, logits, threshold=0.0):\n",
    "    preds = logits > threshold\n",
    "    return (trues == preds).mean()\n",
    "\n",
    "def roc_auc(trues, logits):\n",
    "    return roc_auc_score(trues, logits)\n",
    "\n",
    "def ap(trues, logits):\n",
    "    return average_precision_score(trues, logits)\n",
    "\n",
    "\n",
    "def find_threshold_f1(trues, logits, eps=1e-9):\n",
    "    precision, recall, thresholds = precision_recall_curve(trues, logits)\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + eps)\n",
    "    threshold = float(thresholds[np.argmax(f1_scores)])  \n",
    "    return threshold\n",
    "\n",
    "\n",
    "\n",
    "def calc_metrics(trues, logits):\n",
    "\n",
    "    class_num = 2\n",
    "    bin_trues, bin_logits = to_binary(trues, logits, class_num)\n",
    "\n",
    "    bin_trues, bin_logits = remove_part(bin_trues, bin_logits, fraq=0.1)\n",
    "\n",
    "    threshold = find_threshold_f1(bin_trues, bin_logits, eps=1e-9)\n",
    "    print('Best f1 threshold:', threshold)\n",
    "\n",
    "    result = dict()\n",
    "    result['accuracy'] = calc_accuracy(trues, logits)\n",
    "    result[f'acc_{class_num}_th_0'] = binary_accuracy(bin_trues, bin_logits, threshold=0.0)\n",
    "    result[f'acc_{class_num}_th_opt'] = binary_accuracy(bin_trues, bin_logits, threshold=threshold)\n",
    "    result[f'rocauc_{class_num}'] = roc_auc(bin_trues, bin_logits)\n",
    "    result[f'ap_{class_num}'] = ap(bin_trues, bin_logits)\n",
    "\n",
    "    #result.update(classification_metrics(bin_trues, bin_logits > threshold))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = list()\n",
    "for i in range(num_epochs):\n",
    "    trues, logits = data[i]\n",
    "    metrics = calc_metrics(trues, logits)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "all_metrics = pd.DataFrame(all_metrics).reset_index(drop=True)\n",
    "\n",
    "all_metrics.plot(figsize=(30,5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3460a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(trues, preds, eps=1e-9):   \n",
    "    \n",
    "    trues = np.array(trues) > 0.5\n",
    "    preds = np.array(preds) > 0.5\n",
    "           \n",
    "    tp = (trues & preds).sum()\n",
    "    tn = (~trues & ~preds).sum()\n",
    "    fp = (~trues & preds).sum()\n",
    "    fn = (trues & ~preds).sum()\n",
    "    \n",
    "    result = dict()\n",
    "    result['tp'] = tp\n",
    "    result['tn'] = tn\n",
    "    result['fp'] = fp\n",
    "    result['fn'] = fn\n",
    "    \n",
    "    result['accuracy'] = (trues == preds).mean()\n",
    "    \n",
    "    result['recall'] = tp / (tp + fn + eps)\n",
    "    result['precision'] = tp / (tp + fp + eps)\n",
    "    result['sensitivity'] = tp / (tp + fn + eps)\n",
    "    result['specificity'] = tn / (tn + fp + eps)\n",
    "    result['ppv'] = tp / (tp + fp + eps)\n",
    "    result['npv'] = tn / (tn + fn + eps)\n",
    "    \n",
    "    result['f1'] = 2 * result['recall'] * result['precision'] / (result['recall'] + result['precision'] + eps)\n",
    "    result['ss'] = 2 * result['sensitivity'] * result['specificity'] / (result['sensitivity'] + result['specificity'] + eps)\n",
    "    \n",
    "    result['trues_sum']  = int(trues.sum())\n",
    "    result['trues_percent'] = result['trues_sum'] / trues.shape[0]\n",
    "    \n",
    "    result['preds_sum'] = int(preds.sum())\n",
    "    result['preds_percent'] = result['preds_sum'] / preds.shape[0]\n",
    "    \n",
    "    result['count'] = trues.shape[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
