{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de7009f",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53059d19",
   "metadata": {},
   "source": [
    "- The maximum number of points for this assignment is 10, the minimum number of points is 0.\n",
    "- You have one week to complete the assignment. Once the assignment is submitted you are not allowed to change it.\n",
    "- One week delay is penalized with 1 point.\n",
    "  - Example. The assignment is issued on the 1st January. The deadline without penalization is until 23:59 January 14th (anywhere on Earth). Student A submits his assignment on 22:51 January 6th and is not penalized; student B submits his assignment on 01:13 January 8th and is penalized with 1 point; student C submits his assignment on 3:56 January 16th and is penalized with 2 points and so on.\n",
    "- You have three weeks to compelte the assignment. After three weeks we will not accept solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817317b",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f990dc",
   "metadata": {},
   "source": [
    "In this task you will write a piece of code that\n",
    "creates [ResNet18](https://arxiv.org/abs/1512.03385).\n",
    "ResNet18 is еру deep neural networks devised for image classification.\n",
    "In the histroy of development of computer vision it is \n",
    "a fundamental architecture. \n",
    "The main idea of ResNet-family architecture is to sum\n",
    "an input signal to a computational block $x$ with its output $\\mathcal{F}(x)$.\n",
    "In the paper this type of a connection called \"residual connection\".\n",
    "![Residual connection](residual_connection.png)\n",
    "You will entounter the idea of combining modified signal with the\n",
    "original one later in our course, for instance in U-Nets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1ac72",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239efb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e81c",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 point for both\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_planes  (int): the number of input channels;\n",
    "        out_palnes (int): the number of output channels;\n",
    "        stride     (int, default=1): stride.\n",
    "        \n",
    "    Return:\n",
    "        A two-dimensional convolutional layer with\n",
    "        `in_planes` input channels, `out_planes` output channels,\n",
    "        kernel size 1, stride size `stride`, 0 padding and\n",
    "        without bias parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Your code here. \n",
    "    \"\"\"\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_planes  (int): the number of input channels;\n",
    "        out_palnes (int): the number of output channels;\n",
    "        stride     (int, default=1): stride.\n",
    "        \n",
    "    Return:\n",
    "        A two-dimensional convolutional layer with\n",
    "        `in_planes` input channels, `out_planes` output channels,\n",
    "        kernel size 3, stride size `stride`, padding equals to 1 and\n",
    "        without bias parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Your code here. \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983db2d",
   "metadata": {},
   "source": [
    "## Resnet18 Basic Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e5f14",
   "metadata": {},
   "source": [
    "![resnet_bb.svg](resnet_bb.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Write a piece of code that creates a Basic block for ResNet\n",
    "    architecture.\n",
    "    Basic block has two computational paths: feedforward path and\n",
    "    residual path (see a picture below).\n",
    "    We will utilise function `downsample_basic_block` from above\n",
    "    as a residual path.\n",
    "    Feedforward path consists of consequitive \n",
    "    application of the following five layers:\n",
    "    1. conv3x3 (use `in_planes`, `planes` and `stride` as \n",
    "                parameters for the conv3x3);\n",
    "    2. Batch normalistaion layer with `planes` features;\n",
    "    3. Activation function;\n",
    "    4. conv3x3 (use `planes`, `planes` as input parameters\n",
    "                to conv3x3, keep `stride` by default)\n",
    "    5. Batch normalisation layer with `planes` features;\n",
    "    \n",
    "    Then sum outputs of the residual and feedforward paths \n",
    "    as the picture suggests and return the activated sum (i.e.\n",
    "    apply the activation function to the sum).\n",
    "    \n",
    "    Provide a possibility to use either ReLU \n",
    "    or LeakyReLU or PReLU inside a Basic block .\n",
    "    \n",
    "    Hint:\n",
    "        When you are using ReLU function from Pytorch use can\n",
    "        specify `inplace=True`. In that case the result of the\n",
    "        activation function will be stored in the same tensor, \n",
    "        i.e. you do not need explicitly assign the result of\n",
    "        the inplace operation to some variable. It could help\n",
    "        to decrease the memory consumption sometimes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, relu_type='relu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes   (int): number of input channels to the block;\n",
    "            planes     (int): number of output channels of the block;\n",
    "            stride     (int, default=1): stride for the first convolutional layer;\n",
    "            downsample (nn.Module, default=None): Convolutional layer to \n",
    "                                                  to downsample the residual connection\n",
    "            rely_type  (str, default='relu'): Type of activation function;\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        assert relu_type in ['relu', 'leaky_relu', 'prelu']\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "        # 1 points\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 point\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b08a1",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a20e48",
   "metadata": {},
   "source": [
    "![Activation functions](activations.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17676e64",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        block, \n",
    "        layers, \n",
    "        in_planes=64,\n",
    "        num_classes=100, \n",
    "        relu_type='relu'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ResNet18 comprises an input layer and four consequitive \n",
    "        group of Basic block (layer) that are outputs of the\n",
    "        `self._make_layer` method.\n",
    "        The first layer (not the input one!) has 64 input channels\n",
    "        and twice more, 128, output channels, the next one has 128\n",
    "        input channels and 256 output channels, etc.\n",
    "        When construction the network use\n",
    "        for layer1: stride=1\n",
    "        for layer{2,3,4}: stride=2.\n",
    "        The next layer averages should average input tensor over\n",
    "        the spatial dimensions. Let us think that a batch has shape\n",
    "        [B,C,H,W],  B -- the number of elements in the batch;\n",
    "                    C -- the number of output channels;\n",
    "                    H, W -- height and weight, spatial sizes.\n",
    "        After averaging, your tensor should have size [B,C,1,1].\n",
    "        The final layer is a linear projection from C-dimensional space\n",
    "        into `num_classes`-dimensional one.\n",
    "        \n",
    "        Hint:\n",
    "            1. You may want to use nn.AdaptiveAvgPool2d;\n",
    "        \"\"\"\n",
    "        \n",
    "        self.in_planes = in_planes\n",
    "        self.relu_type = relu_type\n",
    "        self.num_classes = num_classes\n",
    "        self.downsample_block = downsample_basic_block\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        # 2 points\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise modules\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        # 2 points\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block  (nn.Module): Basic block to use;\n",
    "            planes (int): The number of output channels;\n",
    "            blocks (int): How many Basic blocks to repeat;\n",
    "            stride (int, default=1): stride.\n",
    "            \n",
    "        Return:\n",
    "            torch.nn.modules.container.Sequential\n",
    "            \n",
    "        * _make_layer method creates `blocks` copies of the `block`.\n",
    "        * The first `block` has `self.in_planes` input channels\n",
    "            and `planes` output channels;\n",
    "        * Other `blocks-1` block have the same number of\n",
    "            input and output channels, namely `planes`.\n",
    "        * Apply non unit stride ONLY for the first block!\n",
    "        \n",
    "        Hints:\n",
    "            1. Do not forget to use downsample block.\n",
    "                When do you need to use it?\n",
    "            2. Use a list `layers` to store a list of \n",
    "                required blocks;\n",
    "            3. Once the layer is created do not forget to\n",
    "                change the value of `self.inplanes` since\n",
    "                the number of input channels of the\n",
    "                next layer is the same as the number of \n",
    "                output layers of the current layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define downsample\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define layers\n",
    "        layers = []\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def downsample_basic_block(self, in_planes, out_planes, stride):\n",
    "        # 1 point\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes  (int): the number of input channels;\n",
    "            out_palnes (int): the number of output channels;\n",
    "            stride     (int): stride.\n",
    "\n",
    "        Return:\n",
    "            Downsample block comprises two layers:\n",
    "            1. conv1x1(inplanes, outplanes, stride),\n",
    "            2. Batch normalisation block with `outplanes` features.\n",
    "        Hint:\n",
    "            Use nn.Sequential\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" \n",
    "        Your code here. \n",
    "        \"\"\"\n",
    "\n",
    "    def make_input_layer(self, in_channels, out_channels, relu_type):\n",
    "        # 1 points\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channles  (int): the number if input channels;\n",
    "            out_channels (int): the number of output channels;\n",
    "            relu_type    (str): type of an activation function.\n",
    "            \n",
    "        Return:\n",
    "            A sequence of layers:\n",
    "            1. 2D convolution layer with `in_channels` input channels;\n",
    "                `out_channels` output channels, `kernel_size` 7,\n",
    "                `stride` 2, `bias` False. \n",
    "                * * * \n",
    "                What padding should one use in order to half the\n",
    "                spatial sizes of the input?\n",
    "                E.g. \n",
    "                inp = torch.randn(B, C, 64, 64)\n",
    "                conv = nn.Conv2d(C, out_channels, 7, stride=2, padding=???, bias=False)\n",
    "                conv(inp).shape # equals [B, out_channels, 32, 32]\n",
    "                * * * \n",
    "            2. Batch normalisation layer with out_channels features;\n",
    "            3. Activation function;\n",
    "            4. Maximum pooling with `kernel_size` 3, `stride` 2,\n",
    "                `dilation` 1, `ceil_mode` False.\n",
    "                * * * \n",
    "                What padding should one use in order to half the\n",
    "                spatial sizes of the input?\n",
    "                E.g. \n",
    "                inp = torch.randn(B, C, 32, 32)\n",
    "                pooling = nn.MaxPool2d(\n",
    "                    kernel_size=3, stride=2, padding=???, \n",
    "                    dilation=1, ceil_mode=False)\n",
    "                pooling(inp).shape # equals [B, out_channels, 16, 16]\n",
    "                * * * \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 point\n",
    "        \"\"\"\n",
    "        Your code here.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def calc_accuracy(trues, logits):\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return (trues == preds).mean()\n",
    "  \n",
    "def train_epoch(net, dl, criterion, optimizer, device='cuda'):\n",
    "    net.train()\n",
    "    losses = list()\n",
    "    for batch in dl:\n",
    "        images, trues = batch\n",
    "\n",
    "        images = images.to(device)\n",
    "        trues = trues.to(device)\n",
    "\n",
    "        logits = net(images)  \n",
    "\n",
    "        loss = criterion(logits, trues)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "\n",
    "def inference_dl(net, dl, device):\n",
    "    net.eval()\n",
    "    all_trues = list()\n",
    "    all_logits = list()\n",
    "    with torch.no_grad():\n",
    "    for batch in dl:    \n",
    "        images, trues = batch\n",
    "        images = images.to(device)\n",
    "        logits = net(images)\n",
    "\n",
    "        all_trues.append(trues)\n",
    "        all_logits.append(logits)\n",
    "\n",
    "    all_trues = torch.cat(all_trues)\n",
    "    all_logits = torch.cat(all_logits)\n",
    "\n",
    "    return all_trues, all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These hyperparameters might work.\n",
    "# ADjust them according to your computational environment.\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8061c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalisation;\n",
    "\n",
    "all_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "# Datasets and Dataloaders;\n",
    "train_ds = datasets.CIFAR100('../data', train=True, download=True, transform=all_transforms)\n",
    "test_ds = datasets.CIFAR100('../data', train=False, download=True, transform=all_transforms)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Create a network\n",
    "\n",
    "relu_type = \"prelu\"\n",
    "net = ResNet(BasicBlock, [2, 2, 2, 2], relu_type=relu_type)\n",
    "net.to(device)\n",
    "\n",
    "# Define a loss function and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your network\n",
    "\n",
    "valid_accuracy = list()\n",
    "train_losses = list()\n",
    "data = list()\n",
    "\n",
    "print('Epoch:', -1)\n",
    "trues, logits = inference_dl(net, test_dl, device)\n",
    "\n",
    "trues = trues.cpu().numpy()\n",
    "logits = logits.detach().cpu().numpy()\n",
    "\n",
    "accuracy = calc_accuracy(trues, logits)\n",
    "valid_accuracy.append(accuracy)\n",
    "\n",
    "print('Train loss:', 0)\n",
    "print('Valid accuracy:', accuracy)\n",
    "\n",
    "data.append((trues, logits))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    train_eposc_losses = train_epoch(\n",
    "        net, \n",
    "        train_dl, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    train_losses += train_eposc_losses\n",
    "\n",
    "    trues, logits = inference_dl(net, test_dl, device)\n",
    "\n",
    "    trues = trues.cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    accuracy = calc_accuracy(trues, logits)\n",
    "    valid_accuracy.append(accuracy)\n",
    "\n",
    "    print('Train loss:', np.mean(train_eposc_losses))\n",
    "    print('Valid accuracy:', accuracy)\n",
    "\n",
    "    data.append((trues, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f83b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a loss curve and an accuracy curve\n",
    "\n",
    "plt.figure(figsize=(30,5 ))\n",
    "plt.plot(train_losses)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30,5 ))\n",
    "plt.plot(valid_accuracy)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and analyse the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "trues = data[-1][0]\n",
    "preds = np.argmax(data[-1][1], axis=1)\n",
    "\n",
    "cn = confusion_matrix(trues, preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ConfusionMatrixDisplay(cn).plot(ax=ax)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
